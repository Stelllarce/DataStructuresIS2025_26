# Сортиращи алгоритми

## Характеристики и Сравнение

| Алгоритъм | Най-добро | Средно | Най-лошо | Памет | Стабилен? | Метод |
| :--- | :--- | :--- | :--- | :--- | :--- | :--- |
| **Bubble Sort** | $O(n)$ | $O(n^2)$ | $O(n^2)$ | $O(1)$ | Да | Сравняващ (Размяна) |
| **Insertion Sort**| $O(n)$ | $O(n^2)$ | $O(n^2)$ | $O(1)$ | Да | Сравняващ |
| **Selection Sort**| $O(n^2)$ | $O(n^2)$ | $O(n^2)$ | $O(1)$ | Не | Сравняващ |
| **Cocktail Sort** | $O(n)$ | $O(n^2)$ | $O(n^2)$ | $O(1)$ | Да | Сравняващ (Bubble)|
| **Shell Sort** | $O(n \log n)$ | зависи | $O(n^2)$ | $O(1)$ | Не | Сравняващ |
| **Heap Sort** | $O(n \log n)$| $O(n \log n)$| $O(n \log n)$| $O(1)$ | Не | Сравняващ (Селекция) |
| **Merge Sort** | $O(n \log n)$| $O(n \log n)$| $O(n \log n)$| $O(n)$ | Да | Сравняващ (Сливане) |
| **Quick Sort** | $O(n \log n)$| $O(n \log n)$| $O(n^2)$ | $O(\log n)$ | Не | Сравняващ (Разделяне)|
| **Intro Sort** | $O(n \log n)$| $O(n \log n)$| $O(n \log n)$| $O(\log n)$ | Не | Хибриден |
| **Counting Sort** | $O(n+k)$ | $O(n+k)$ | $O(n+k)$ | $O(k)$ | Да | Броене |
| **Bucket Sort** | $O(n+k)$ | $O(n)$ | $O(n^2)$ | $O(n)$ | Да | Разпределяне |
| **Radix Sort** | $O(nk)$ | $O(nk)$ | $O(nk)$ | $O(n+k)$ | Да | Цифров |

---

## Oписание на алгоритмите

[<h3>За имплементация на първите 3 прости алгоритъма виж тук](https://github.com/Stelllarce/UpInformaticsSeminarPracticum2024-25/tree/main/Seminar/Week08)

### 1. Counting Sort (Сортиране чрез броене)
**Принцип на действие:**  
Това е алгоритъм за сортиране на цели числа, който не използва сравнения. Той разчита на знанието за диапазона на числата (от `min` до `max`).
1. Създава се помощен масив `count` с размер `max - min + 1`.
2. Обхожда се входния масив и за всяко число се увеличава брояча на съответния индекс в `count`.
3. Масивът `count` се кумулира (prefix sum), за да определи правилните позиции на елементите в изходния масив.
4. Входният масив се обхожда отново (обикновено отзад напред за стабилност), и елементите се поставят на правилните места.

*   **Време:** $O(n + k)$, където $k$ е диапазонът на числата.
*   **Памет:** $O(k)$ за помощния масив.
*   **Стабилност:** Да (ако се имплементира правилно с обхождане отзад напред).
*   **Приложение:** Когато $k$ е сравнително малко (напр. сортиране на оценки от 2 до 6, дни в годината). Ако $k$ е много голямо (напр. $10^9$), алгоритъмът е неефективен по памет.

### 2. Radix Sort (Поразрядно сортиране)
**Принцип на действие:**  
Разширение на Counting Sort, което позволява сортиране на големи числа, като ги разбива на цифри (разреди). Основната идея е да се сортират числата първо по най-маловажната цифра (единици), после по десетици, стотици и т.н.
За сортирането на всеки разряд се използва стабилен алгоритъм (обикновено Counting Sort).

*   **Време:** $O(d \cdot (n + b))$, където $d$ е броят цифри, а $b$ е базата (напр. 10).
*   **Памет:** $O(n + b)$.
*   **Стабилност:** Да.
*   **Приложение:** Сортиране на цели числа с фиксирана дължина или стрингове. Много бърз, когато числата са големи, но не прекалено дълги.

### 3. Bucket Sort (Сортиране с кофи)
**Принцип на действие:**  
Разпределя елементите в краен брой "кофи" (buckets) на базата на тяхната стойност.
1. Създава се масив от празни кофи.
2. Всеки елемент от входа се слага в съответната кофа (чрез формула, напр. `floor(n * value)`).
3. Всяка кофа се сортира индивидуално (често с Insertion Sort или рекурсивно).
4. Кофите се обединяват последователно.

*   **Време:** $O(n + k)$ средно, ако данните са равномерно разпределени. В най-лошия случай (всички в една кофа): $O(n^2)$.
*   **Памет:** $O(n)$.
*   **Стабилност:** Да (ако алгоритъмът вътре в кофата е стабилен).
*   **Приложение:** Когато знаем, че данните са равномерно разпределени в диапазон (напр. float числа в `[0, 1)`).

### 4. Heap Sort (Пирамидално сортиране)
**Принцип на действие:**  
Използва структурата от данни **Binary Heap** (Двоична пирамида).
1. Входният масив се превръща в Max-Heap (родителят е винаги по-голям от децата).
2. Най-големият елемент (коренът) се разменя с последния елемент на масива и се "изважда" от пирамидата (размерът на пирамидата намалява с 1).
3. Извиква се процедура `heapify` за корена, за да се възстанови свойството на пирамидата.
4. Стъпки 2 и 3 се повтарят до изчерпване на пирамидата.

*   **Време:** $O(n \log n)$ във всички случаи.
*   **Памет:** $O(1)$ (In-place).
*   **Стабилност:** Не.
*   **Приложение:** Когато паметта е ограничена и се изисква гарантирано $O(n \log n)$ време.

### 5. Quick Sort (Бързо сортиране)
**Принцип на действие:**  
Алгоритъм от типа "Разделяй и владей".
1. Избира се опорен елемент (**pivot**).
2. Масивът се пренарежда (**partitioning**), така че всички елементи по-малки от пивота отиват вляво, а по-големите – вдясно. Пивотът застава на финалната си сортирана позиция.
3. Рекурсивно се прилага същото за лявата и дясната част.

*   **Време:** Средно $O(n \log n)$. Най-лошо $O(n^2)$ (ако масивът е вече сортиран или има много дубликати и пивотът е избран лошо).
*   **Памет:** $O(\log n)$ за стека на рекурсията.
*   **Стабилност:** Не.
*   **Приложение:** Един от най-бързите алгоритми на практика за общо ползване.

### 6. Merge Sort (Сортиране чрез сливане)
**Принцип на действие:**  
Класически "Разделяй и владей".
1. Масивът се разделя на две равни половини.
2. Всяка половина се сортира рекурсивно.
3. Двете сортирани половини се комбинират (**merge**) в един сортиран масив.

*   **Време:** $O(n \log n)$ гарантирано.
*   **Памет:** $O(n)$ (необходим е помощен масив за сливането).
*   **Стабилност:** Да.
*   **Приложение:** Когато стабилността е важна или се сортират свързани списъци (където не изисква допълнителна памет).

### 7. Cocktail Sort (Shaker Sort)
**Принцип на действие:**  
Вариация на **Bubble Sort**. Вместо да минава само в една посока (отляво надясно), алгоритъмът минава в двете посоки последователно.
1. Минава напред и избутва най-големият елемент в края (като Bubble Sort).
2. Минава назад и избутва най-малкия елемент в началото.
3. Границите се стесняват от двете страни.

*   **Време:** $O(n^2)$ средно и най-лошо. $O(n)$ най-добро (почти сортиран масив).
*   **Памет:** $O(1)$.
*   **Стабилност:** Да.
*   **Приложение:** Подобрено поведение спрямо Bubble Sort.

### 8. Shell Sort
**Принцип на действие:**  
Оптимизация на **Insertion Sort**. Позволява размяна на елементи, които са далеч един от друг.
1. Избира се серия от "стъпки" (gaps), напр. $n/2, n/4, \dots, 1$.
2. За всяка стъпка се извършва Insertion Sort върху елементите, отстоящи на разстояние `gap` един от друг.
3. Последната стъпка е винаги 1, което е стандартен Insertion Sort, но върху почти сортиран масив (което е много бързо).

*   **Време:** Зависи от gap sequence. Обикновено между $O(n \log^2 n)$ и $O(n^{1.5})$. Най-лошо $O(n^2)$.
*   **Памет:** $O(1)$.
*   **Стабилност:** Не.
*   **Приложение:** За средно големи масиви, лесна имплементация, добра производителност без допълнителна памет.

### 9. Intro Sort (Introspective Sort)
**Принцип на действие:**  
Хибриден алгоритъм, който комбинира най-доброто от Quick Sort, Heap Sort и Insertion Sort. Използва се в стандартните библиотеки (напр. `std::sort` в C++).
1. Започва с **Quick Sort**.
2. Следи дълбочината на рекурсията. Ако тя надвиши $2 \cdot \log n$ (сигнал, че Quick Sort деградира към лошия случай), превключва на **Heap Sort**.
3. За много малки подмасиви (напр. < 16 елемента) превключва на **Insertion Sort**, защото той е най-бърз за малки данни.

*   **Време:** $O(n \log n)$ гарантирано (worst-case).
*   **Памет:** $O(\log n)$.
*   **Стабилност:** Не.
*   **Приложение:** `std::sort` в C++ STL.

## Мемета-алгоритми

### 10. Bogo Sort (Permutation Sort)
**Принцип на действие:**  
Най-неефективният алгоритъм (не съвсем, има и [bogobogosort](https://www.dangermouse.net/esoteric/bogobogosort.html), а wikipeadia твърди че съществува и "Heat Death sort", но за него не намирам нищо)
1. Проверява дали масивът е сортиран.
2. Ако не е, разбърква (shuffle) масива на случаен принцип.
3. Повтаря.

*   **Време:** Средно $O(n \cdot n!)$. Теоретично може никога да не завърши.
*   **Памет:** $O(1)$.
*   **Приложение:** Що не.

### 11. Sleep Sort
**Принцип на действие:**  
Алгоритъм, базиран на многонишковост и време.
1. За всяко число $x$ от масива се стартира нова нишка (thread).
2. Нишката "спи" за време, пропорционално на $x$ (напр. $x$ милисекунди).
3. След като се събуди, нишката принтира или записва числото.
4. Тъй като по-малките числа "спят" по-малко, те ще се "събудят" първи и ще се наредят първи.

*   **Време:** $O(max(element) + n)$. Зависи от най-голямото число, не от броя елементи.
*   **Проблеми:** Не работи с отрицателни числа; не е точен заради начина, по който операционната система планира нишките (race conditions).
*   **Приложение:** Почивка.

